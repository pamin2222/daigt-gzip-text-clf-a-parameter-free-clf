{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3998a05",
   "metadata": {
    "papermill": {
     "duration": 0.005315,
     "end_time": "2023-11-25T08:13:47.753282",
     "exception": false,
     "start_time": "2023-11-25T08:13:47.747967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Addressing this task by employing the Normalized Compression Distance (NCD) method, utilizing gzip compression to measure text similarity\n",
    "\n",
    "Reference:\n",
    "- \"Low-Resource\" Text Classification: A Parameter-Free Classification Method with Compressors paper (https://aclanthology.org/2023.findings-acl.426/)\n",
    "- https://github.com/rasbt/nn_plus_gzip/blob/main/1_2_nn_plus_gzip_fix-tie-breaking.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecc0994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:47.768114Z",
     "iopub.status.busy": "2023-11-25T08:13:47.766795Z",
     "iopub.status.idle": "2023-11-25T08:13:48.196900Z",
     "shell.execute_reply": "2023-11-25T08:13:48.195748Z"
    },
    "papermill": {
     "duration": 0.439297,
     "end_time": "2023-11-25T08:13:48.199765",
     "exception": false,
     "start_time": "2023-11-25T08:13:47.760468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff2b236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:48.210979Z",
     "iopub.status.busy": "2023-11-25T08:13:48.210460Z",
     "iopub.status.idle": "2023-11-25T08:13:50.618498Z",
     "shell.execute_reply": "2023-11-25T08:13:50.617622Z"
    },
    "papermill": {
     "duration": 2.41662,
     "end_time": "2023-11-25T08:13:50.621161",
     "exception": false,
     "start_time": "2023-11-25T08:13:48.204541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\n",
    "external_train = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n",
    "external_train.rename(columns={'generated': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9cf9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:50.632967Z",
     "iopub.status.busy": "2023-11-25T08:13:50.632167Z",
     "iopub.status.idle": "2023-11-25T08:13:50.636714Z",
     "shell.execute_reply": "2023-11-25T08:13:50.635829Z"
    },
    "papermill": {
     "duration": 0.012867,
     "end_time": "2023-11-25T08:13:50.639064",
     "exception": false,
     "start_time": "2023-11-25T08:13:50.626197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q language-tool-python --no-index --find-links ../input/daigt-misc/\n",
    "# !mkdir -p /root/.cache/language_tool_python/\n",
    "# !cp -r /kaggle/input/daigt-misc/lang57/LanguageTool-5.7 /root/.cache/language_tool_python/LanguageTool-5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fa91a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:50.649643Z",
     "iopub.status.busy": "2023-11-25T08:13:50.649294Z",
     "iopub.status.idle": "2023-11-25T08:13:52.654347Z",
     "shell.execute_reply": "2023-11-25T08:13:52.653260Z"
    },
    "papermill": {
     "duration": 2.01356,
     "end_time": "2023-11-25T08:13:52.657246",
     "exception": false,
     "start_time": "2023-11-25T08:13:50.643686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏕👨🐶💀□ü🚂📹☀ち🐢👮🥶🔭ê🏽🛬禁🐭🥖こ😍使🙀🏃📸💥�🌱🎭🏈🚭🏫🥳💃♂🏢🌠’🍞🐦🎤❄🏟🎣は🌮🏜🙌是🚔🤔😤🥕🤓取🎵护🍖🏙🏰🥑😊💁💇😎☹🧭🛫上🥦🎸🍎🏳时🔋🌎éí👂🍜😔💊😉💼🥁🐱🍔💭°🧠📰🛋😲🧬🤯驶…🌳完🔬🌧🌭🌨😡🌷中🍝ん😻🔧📝🐴📷驾📉─🚨🎧😕🍣😩🌊😋😵🙃所🎾🚀🤜🕺✨🤛🍿🇧🏯🎶🐰🍳¬🤢💸🥤法🎄🙄う😨💦🤟⏰🌄🚚🏔📊р😱🤪​🏛😒安ç🌸🧚🌲🧦🌞😅🏼将都👥🛣💚🛑合📄🙅🤖🧀╯🇪🛠ã用🇵🛍👍💰🎮–с🦸🇺🧽必保🐕👇о道力^💅📣🏏”📞🥛📺り🐻🔍🐆的🐠🤤👏🍽📦。🕒🤫🙋路🐧👻🇷せ👬🌏🗳💯司🔮🍰🕹🎅🚌🚴🐾🛸—和📧🍲🎊该有🏨🤞📱🤷🦐👫🙏🧐д🚫🤣🚪🚣😴🌟🥔👦👌一😓♀“唯🎈🧖🔑须👧🏠👋🍋🥟🍟🎉🚕🌈🦎🤘💧选🌽🦁⚽🧙🎨😖あ😜手🍓📖💨😳🎩😝🇸🏡ā🍁🌯😘🥭🇯\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/siddhvr/llm-detect-ai-gt-sub\n",
    "not_persuade_df = train[train['source'] != 'persuade_corpus']\n",
    "persuade_df = train[train['source'] == 'persuade_corpus']\n",
    "sampled_persuade_df = persuade_df.sample(n=6000, random_state=42)\n",
    "\n",
    "all_human = set(list(''.join(sampled_persuade_df.text.to_list())))\n",
    "other = set(list(''.join(not_persuade_df.text.to_list())))\n",
    "chars_to_remove = ''.join([x for x in other if x not in all_human])\n",
    "print(chars_to_remove)\n",
    "\n",
    "translation_table = str.maketrans('', '', chars_to_remove)\n",
    "def remove_chars(s):\n",
    "    return s.translate(translation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b0c435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:52.669813Z",
     "iopub.status.busy": "2023-11-25T08:13:52.669438Z",
     "iopub.status.idle": "2023-11-25T08:13:56.200745Z",
     "shell.execute_reply": "2023-11-25T08:13:56.199700Z"
    },
    "papermill": {
     "duration": 3.54028,
     "end_time": "2023-11-25T08:13:56.203356",
     "exception": false,
     "start_time": "2023-11-25T08:13:52.663076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.concat([train,external_train])\n",
    "train['text'] = train['text'].apply(remove_chars)\n",
    "train['text'] = train['text'].str.replace('\\n', '')\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "test['text'] = test['text'].str.replace('\\n', '')\n",
    "test['text'] = test['text'].apply(remove_chars)\n",
    "#correct_df(test)\n",
    "#df = pd.concat([train['text'], test['text']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af323766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:56.215513Z",
     "iopub.status.busy": "2023-11-25T08:13:56.215056Z",
     "iopub.status.idle": "2023-11-25T08:13:56.233431Z",
     "shell.execute_reply": "2023-11-25T08:13:56.232353Z"
    },
    "papermill": {
     "duration": 0.027399,
     "end_time": "2023-11-25T08:13:56.235955",
     "exception": false,
     "start_time": "2023-11-25T08:13:56.208556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ff669174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label prompt_name  \\\n",
       "1373  There has been a fuss about the Elector Colleg...      0         NaN   \n",
       "1374  Limiting car usage has many advantages. Such a...      0         NaN   \n",
       "1375  There's a new trend that has been developing f...      0         NaN   \n",
       "1376  As we all know cars are a big part of our soci...      0         NaN   \n",
       "1377  Cars have been around since the 1800's and hav...      0         NaN   \n",
       "\n",
       "     source RDizzl3_seven        id  prompt_id  \n",
       "1373    NaN           NaN  fe6ff9a5        1.0  \n",
       "1374    NaN           NaN  ff669174        0.0  \n",
       "1375    NaN           NaN  ffa247e0        0.0  \n",
       "1376    NaN           NaN  ffc237e9        0.0  \n",
       "1377    NaN           NaN  ffe1ca0d        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bec4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:56.247896Z",
     "iopub.status.busy": "2023-11-25T08:13:56.247545Z",
     "iopub.status.idle": "2023-11-25T08:14:03.002442Z",
     "shell.execute_reply": "2023-11-25T08:14:03.001366Z"
    },
    "papermill": {
     "duration": 6.764042,
     "end_time": "2023-11-25T08:14:03.005205",
     "exception": false,
     "start_time": "2023-11-25T08:13:56.241163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def compress_text(text):\n",
    "    return len(gzip.compress(text.encode()))\n",
    "\n",
    "# Pre-compute the compressed lengths for training data\n",
    "train['compressed_length'] = train['text'].apply(compress_text)\n",
    "\n",
    "def calculate_ncd(c_text1, c_text2, combined_text):\n",
    "    c_combined = compress_text(combined_text)\n",
    "    return (c_combined - min(c_text1, c_text2)) / max(c_text1, c_text2)\n",
    "\n",
    "def classify_text(test_text, training_data, k=2):\n",
    "    c_test_text = compress_text(test_text)\n",
    "    distances = []\n",
    "\n",
    "    for _, row in training_data.iterrows():\n",
    "        c_train_text = row['compressed_length']\n",
    "        combined_text = test_text + \" \" + row['text']\n",
    "        ncd = calculate_ncd(c_test_text, c_train_text, combined_text)\n",
    "        distances.append(ncd)\n",
    "\n",
    "    sorted_idx = np.argsort(np.array(distances))\n",
    "    top_k_class = np.array(training_data['label'])[sorted_idx[:k]]\n",
    "    predicted_class = Counter(top_k_class).most_common(1)[0][0]\n",
    "    return predicted_class\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def batch_classify_texts(test_texts, training_data, k=2, sample_size=None):\n",
    "    if sample_size is not None and sample_size < len(training_data):\n",
    "        # Perform stratified sampling\n",
    "        _, stratified_sample = train_test_split(\n",
    "            training_data, \n",
    "            test_size=sample_size, \n",
    "            stratify=training_data['label'], \n",
    "            random_state=42\n",
    "        )\n",
    "        training_data = stratified_sample\n",
    "\n",
    "    probabilities = []\n",
    "    for test_text in test_texts:\n",
    "        c_test_text = compress_text(test_text)\n",
    "        distances = []\n",
    "\n",
    "        for _, row in training_data.iterrows():\n",
    "            c_train_text = row['compressed_length']\n",
    "            combined_text = test_text + \" \" + row['text']\n",
    "            ncd = calculate_ncd(c_test_text, c_train_text, combined_text)\n",
    "            distances.append(ncd)\n",
    "\n",
    "        sorted_idx = np.argsort(np.array(distances))\n",
    "        top_k_class = np.array(training_data['label'])[sorted_idx[:k]]\n",
    "        predicted_class = Counter(top_k_class).most_common(1)[0][0]\n",
    "        probabilities.append(predicted_class)\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def estimate_time_left(start_time, current_iter, total_iter):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_iter = elapsed_time / current_iter\n",
    "    remaining_iters = total_iter - current_iter\n",
    "    estimated_time_left = avg_time_per_iter * remaining_iters\n",
    "    return estimated_time_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c3557f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:14:03.018072Z",
     "iopub.status.busy": "2023-11-25T08:14:03.017695Z",
     "iopub.status.idle": "2023-11-25T08:14:55.369975Z",
     "shell.execute_reply": "2023-11-25T08:14:55.368537Z"
    },
    "papermill": {
     "duration": 52.362874,
     "end_time": "2023-11-25T08:14:55.373631",
     "exception": false,
     "start_time": "2023-11-25T08:14:03.010757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing single evaluation:  50%|█████     | 1/2 [00:25<00:25, 25.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/2, Time left (est.): 25.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing single evaluation: 100%|██████████| 2/2 [00:52<00:00, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/2, Time left (est.): 0.00 seconds\n",
      "Single Evaluation AUROC Score: 0.9366697559468645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_k_fold = False\n",
    "debug_mode = True\n",
    "debug_size = 1000\n",
    "batch_size = 100\n",
    "\n",
    "if debug_mode:\n",
    "    debug_train = train.sample(n=debug_size, random_state=42)\n",
    "else:\n",
    "    debug_train = train\n",
    "\n",
    "if use_k_fold:\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    auroc_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(debug_train)):\n",
    "        start_time = time.time()\n",
    "        train_fold, val_fold = debug_train.iloc[train_index], debug_train.iloc[val_index]\n",
    "        val_texts = [text for text in val_fold['text']]\n",
    "        total_batches = len(val_texts) // batch_size + (len(val_texts) % batch_size != 0)\n",
    "\n",
    "        probabilities = []\n",
    "        for i in tqdm(range(total_batches), desc=f\"Processing fold {fold + 1}\"):\n",
    "            batch_texts = val_texts[i*batch_size:(i+1)*batch_size]\n",
    "            batch_probabilities = batch_classify_texts(batch_texts, train_fold, k=2)\n",
    "            probabilities.extend(batch_probabilities)\n",
    "\n",
    "            time_left = estimate_time_left(start_time, i + 1, total_batches)\n",
    "            print(f\"Fold {fold + 1}, Batch {i + 1}/{total_batches}, Time left (est.): {time_left:.2f} seconds\")\n",
    "\n",
    "        fold_auroc_score = roc_auc_score(val_fold['label'].values, probabilities)\n",
    "        auroc_scores.append(fold_auroc_score)\n",
    "\n",
    "    average_auroc_score = sum(auroc_scores) / len(auroc_scores)\n",
    "    print(\"Average AUROC Score:\", average_auroc_score)\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    train_single, val_single = train_test_split(debug_train, test_size=0.2, random_state=42)\n",
    "    val_texts = [text for text in val_single['text']]\n",
    "    total_batches = len(val_texts) // batch_size + (len(val_texts) % batch_size != 0)\n",
    "\n",
    "    probabilities = []\n",
    "    for i in tqdm(range(total_batches), desc=\"Processing single evaluation\"):\n",
    "        batch_texts = val_texts[i*batch_size:(i+1)*batch_size]\n",
    "        batch_probabilities = batch_classify_texts(batch_texts, train_single, k=2)\n",
    "        probabilities.extend(batch_probabilities)\n",
    "\n",
    "        time_left = estimate_time_left(start_time, i + 1, total_batches)\n",
    "        print(f\"Batch {i + 1}/{total_batches}, Time left (est.): {time_left:.2f} seconds\")\n",
    "\n",
    "    single_auroc_score = roc_auc_score(val_single['label'].values, probabilities)\n",
    "    print(\"Single Evaluation AUROC Score:\", single_auroc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f9ed59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:14:55.387943Z",
     "iopub.status.busy": "2023-11-25T08:14:55.386927Z",
     "iopub.status.idle": "2023-11-25T08:14:55.544509Z",
     "shell.execute_reply": "2023-11-25T08:14:55.543378Z"
    },
    "papermill": {
     "duration": 0.168251,
     "end_time": "2023-11-25T08:14:55.547741",
     "exception": false,
     "start_time": "2023-11-25T08:14:55.379490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test predictions: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# Generating predictions for the test set\n",
    "batch_size = 100\n",
    "sample_train_size = 150  # Adjust as needed (larger = slower)\n",
    "\n",
    "test_probabilities = []\n",
    "for i in tqdm.tqdm(range(0, len(test), batch_size), desc=\"Generating test predictions\"):\n",
    "    batch_texts = test['text'][i:i+batch_size].tolist()\n",
    "    batch_probabilities = batch_classify_texts(batch_texts, train, k=2, sample_size=sample_train_size)\n",
    "    test_probabilities.extend(batch_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a271affa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:14:55.562900Z",
     "iopub.status.busy": "2023-11-25T08:14:55.561808Z",
     "iopub.status.idle": "2023-11-25T08:14:55.574285Z",
     "shell.execute_reply": "2023-11-25T08:14:55.573052Z"
    },
    "papermill": {
     "duration": 0.023173,
     "end_time": "2023-11-25T08:14:55.577090",
     "exception": false,
     "start_time": "2023-11-25T08:14:55.553917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the submission file\n",
    "test['generated'] = test_probabilities\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'generated': test['generated']\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3945154,
     "sourceId": 6865136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.902231,
   "end_time": "2023-11-25T08:14:56.205474",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-25T08:13:44.303243",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
