{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3998a05",
   "metadata": {
    "papermill": {
     "duration": 0.005315,
     "end_time": "2023-11-25T08:13:47.753282",
     "exception": false,
     "start_time": "2023-11-25T08:13:47.747967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Addressing this task by employing the Normalized Compression Distance (NCD) method, utilizing gzip compression to measure text similarity\n",
    "\n",
    "Reference:\n",
    "- \"Low-Resource\" Text Classification: A Parameter-Free Classification Method with Compressors paper (https://aclanthology.org/2023.findings-acl.426/)\n",
    "- https://github.com/rasbt/nn_plus_gzip/blob/main/1_2_nn_plus_gzip_fix-tie-breaking.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecc0994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:47.768114Z",
     "iopub.status.busy": "2023-11-25T08:13:47.766795Z",
     "iopub.status.idle": "2023-11-25T08:13:48.196900Z",
     "shell.execute_reply": "2023-11-25T08:13:48.195748Z"
    },
    "papermill": {
     "duration": 0.439297,
     "end_time": "2023-11-25T08:13:48.199765",
     "exception": false,
     "start_time": "2023-11-25T08:13:47.760468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff2b236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:48.210979Z",
     "iopub.status.busy": "2023-11-25T08:13:48.210460Z",
     "iopub.status.idle": "2023-11-25T08:13:50.618498Z",
     "shell.execute_reply": "2023-11-25T08:13:50.617622Z"
    },
    "papermill": {
     "duration": 2.41662,
     "end_time": "2023-11-25T08:13:50.621161",
     "exception": false,
     "start_time": "2023-11-25T08:13:48.204541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\n",
    "external_train = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n",
    "external_train.rename(columns={'generated': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9cf9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:50.632967Z",
     "iopub.status.busy": "2023-11-25T08:13:50.632167Z",
     "iopub.status.idle": "2023-11-25T08:13:50.636714Z",
     "shell.execute_reply": "2023-11-25T08:13:50.635829Z"
    },
    "papermill": {
     "duration": 0.012867,
     "end_time": "2023-11-25T08:13:50.639064",
     "exception": false,
     "start_time": "2023-11-25T08:13:50.626197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q language-tool-python --no-index --find-links ../input/daigt-misc/\n",
    "# !mkdir -p /root/.cache/language_tool_python/\n",
    "# !cp -r /kaggle/input/daigt-misc/lang57/LanguageTool-5.7 /root/.cache/language_tool_python/LanguageTool-5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fa91a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:50.649643Z",
     "iopub.status.busy": "2023-11-25T08:13:50.649294Z",
     "iopub.status.idle": "2023-11-25T08:13:52.654347Z",
     "shell.execute_reply": "2023-11-25T08:13:52.653260Z"
    },
    "papermill": {
     "duration": 2.01356,
     "end_time": "2023-11-25T08:13:52.657246",
     "exception": false,
     "start_time": "2023-11-25T08:13:50.643686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•ğŸ‘¨ğŸ¶ğŸ’€â–¡Ã¼ğŸš‚ğŸ“¹â˜€ã¡ğŸ¢ğŸ‘®ğŸ¥¶ğŸ”­ÃªğŸ½ğŸ›¬ç¦ğŸ­ğŸ¥–ã“ğŸ˜ä½¿ğŸ™€ğŸƒğŸ“¸ğŸ’¥ï¿½ğŸŒ±ğŸ­ğŸˆğŸš­ğŸ«ğŸ¥³ğŸ’ƒâ™‚ğŸ¢ğŸŒ â€™ğŸğŸ¦ğŸ¤â„ğŸŸğŸ£ã¯ğŸŒ®ğŸœğŸ™Œæ˜¯ğŸš”ğŸ¤”ğŸ˜¤ğŸ¥•ğŸ¤“å–ğŸµæŠ¤ğŸ–ğŸ™ğŸ°ğŸ¥‘ğŸ˜ŠğŸ’ğŸ’‡ğŸ˜â˜¹ğŸ§­ğŸ›«ä¸ŠğŸ¥¦ğŸ¸ğŸğŸ³æ—¶ğŸ”‹ğŸŒÃ©Ã­ğŸ‘‚ğŸœğŸ˜”ğŸ’ŠğŸ˜‰ğŸ’¼ğŸ¥ğŸ±ğŸ”ğŸ’­Â°ğŸ§ ğŸ“°ğŸ›‹ğŸ˜²ğŸ§¬ğŸ¤¯é©¶â€¦ğŸŒ³å®ŒğŸ”¬ğŸŒ§ğŸŒ­ğŸŒ¨ğŸ˜¡ğŸŒ·ä¸­ğŸã‚“ğŸ˜»ğŸ”§ğŸ“ğŸ´ğŸ“·é©¾ğŸ“‰â”€ğŸš¨ğŸ§ğŸ˜•ğŸ£ğŸ˜©ğŸŒŠğŸ˜‹ğŸ˜µğŸ™ƒæ‰€ğŸ¾ğŸš€ğŸ¤œğŸ•ºâœ¨ğŸ¤›ğŸ¿ğŸ‡§ğŸ¯ğŸ¶ğŸ°ğŸ³Â¬ğŸ¤¢ğŸ’¸ğŸ¥¤æ³•ğŸ„ğŸ™„ã†ğŸ˜¨ğŸ’¦ğŸ¤Ÿâ°ğŸŒ„ğŸššğŸ”ğŸ“ŠÑ€ğŸ˜±ğŸ¤ªâ€‹ğŸ›ğŸ˜’å®‰Ã§ğŸŒ¸ğŸ§šğŸŒ²ğŸ§¦ğŸŒğŸ˜…ğŸ¼å°†éƒ½ğŸ‘¥ğŸ›£ğŸ’šğŸ›‘åˆğŸ“„ğŸ™…ğŸ¤–ğŸ§€â•¯ğŸ‡ªğŸ› Ã£ç”¨ğŸ‡µğŸ›ğŸ‘ğŸ’°ğŸ®â€“ÑğŸ¦¸ğŸ‡ºğŸ§½å¿…ä¿ğŸ•ğŸ‘‡Ğ¾é“åŠ›^ğŸ’…ğŸ“£ğŸâ€ğŸ“ğŸ¥›ğŸ“ºã‚ŠğŸ»ğŸ”ğŸ†çš„ğŸ ğŸ¤¤ğŸ‘ğŸ½ğŸ“¦ã€‚ğŸ•’ğŸ¤«ğŸ™‹è·¯ğŸ§ğŸ‘»ğŸ‡·ã›ğŸ‘¬ğŸŒğŸ—³ğŸ’¯å¸ğŸ”®ğŸ°ğŸ•¹ğŸ…ğŸšŒğŸš´ğŸ¾ğŸ›¸â€”å’ŒğŸ“§ğŸ²ğŸŠè¯¥æœ‰ğŸ¨ğŸ¤ğŸ“±ğŸ¤·ğŸ¦ğŸ‘«ğŸ™ğŸ§Ğ´ğŸš«ğŸ¤£ğŸšªğŸš£ğŸ˜´ğŸŒŸğŸ¥”ğŸ‘¦ğŸ‘Œä¸€ğŸ˜“â™€â€œå”¯ğŸˆğŸ§–ğŸ”‘é¡»ğŸ‘§ğŸ ğŸ‘‹ğŸ‹ğŸ¥ŸğŸŸğŸ‰ğŸš•ğŸŒˆğŸ¦ğŸ¤˜ğŸ’§é€‰ğŸŒ½ğŸ¦âš½ğŸ§™ğŸ¨ğŸ˜–ã‚ğŸ˜œæ‰‹ğŸ“ğŸ“–ğŸ’¨ğŸ˜³ğŸ©ğŸ˜ğŸ‡¸ğŸ¡ÄğŸğŸŒ¯ğŸ˜˜ğŸ¥­ğŸ‡¯\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/siddhvr/llm-detect-ai-gt-sub\n",
    "not_persuade_df = train[train['source'] != 'persuade_corpus']\n",
    "persuade_df = train[train['source'] == 'persuade_corpus']\n",
    "sampled_persuade_df = persuade_df.sample(n=6000, random_state=42)\n",
    "\n",
    "all_human = set(list(''.join(sampled_persuade_df.text.to_list())))\n",
    "other = set(list(''.join(not_persuade_df.text.to_list())))\n",
    "chars_to_remove = ''.join([x for x in other if x not in all_human])\n",
    "print(chars_to_remove)\n",
    "\n",
    "translation_table = str.maketrans('', '', chars_to_remove)\n",
    "def remove_chars(s):\n",
    "    return s.translate(translation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b0c435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:52.669813Z",
     "iopub.status.busy": "2023-11-25T08:13:52.669438Z",
     "iopub.status.idle": "2023-11-25T08:13:56.200745Z",
     "shell.execute_reply": "2023-11-25T08:13:56.199700Z"
    },
    "papermill": {
     "duration": 3.54028,
     "end_time": "2023-11-25T08:13:56.203356",
     "exception": false,
     "start_time": "2023-11-25T08:13:52.663076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.concat([train,external_train])\n",
    "train['text'] = train['text'].apply(remove_chars)\n",
    "train['text'] = train['text'].str.replace('\\n', '')\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "test['text'] = test['text'].str.replace('\\n', '')\n",
    "test['text'] = test['text'].apply(remove_chars)\n",
    "#correct_df(test)\n",
    "#df = pd.concat([train['text'], test['text']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af323766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:56.215513Z",
     "iopub.status.busy": "2023-11-25T08:13:56.215056Z",
     "iopub.status.idle": "2023-11-25T08:13:56.233431Z",
     "shell.execute_reply": "2023-11-25T08:13:56.232353Z"
    },
    "papermill": {
     "duration": 0.027399,
     "end_time": "2023-11-25T08:13:56.235955",
     "exception": false,
     "start_time": "2023-11-25T08:13:56.208556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>source</th>\n",
       "      <th>RDizzl3_seven</th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ff669174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label prompt_name  \\\n",
       "1373  There has been a fuss about the Elector Colleg...      0         NaN   \n",
       "1374  Limiting car usage has many advantages. Such a...      0         NaN   \n",
       "1375  There's a new trend that has been developing f...      0         NaN   \n",
       "1376  As we all know cars are a big part of our soci...      0         NaN   \n",
       "1377  Cars have been around since the 1800's and hav...      0         NaN   \n",
       "\n",
       "     source RDizzl3_seven        id  prompt_id  \n",
       "1373    NaN           NaN  fe6ff9a5        1.0  \n",
       "1374    NaN           NaN  ff669174        0.0  \n",
       "1375    NaN           NaN  ffa247e0        0.0  \n",
       "1376    NaN           NaN  ffc237e9        0.0  \n",
       "1377    NaN           NaN  ffe1ca0d        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bec4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:13:56.247896Z",
     "iopub.status.busy": "2023-11-25T08:13:56.247545Z",
     "iopub.status.idle": "2023-11-25T08:14:03.002442Z",
     "shell.execute_reply": "2023-11-25T08:14:03.001366Z"
    },
    "papermill": {
     "duration": 6.764042,
     "end_time": "2023-11-25T08:14:03.005205",
     "exception": false,
     "start_time": "2023-11-25T08:13:56.241163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def compress_text(text):\n",
    "    return len(gzip.compress(text.encode()))\n",
    "\n",
    "# Pre-compute the compressed lengths for training data\n",
    "train['compressed_length'] = train['text'].apply(compress_text)\n",
    "\n",
    "def calculate_ncd(c_text1, c_text2, combined_text):\n",
    "    c_combined = compress_text(combined_text)\n",
    "    return (c_combined - min(c_text1, c_text2)) / max(c_text1, c_text2)\n",
    "\n",
    "def classify_text(test_text, training_data, k=2):\n",
    "    c_test_text = compress_text(test_text)\n",
    "    distances = []\n",
    "\n",
    "    for _, row in training_data.iterrows():\n",
    "        c_train_text = row['compressed_length']\n",
    "        combined_text = test_text + \" \" + row['text']\n",
    "        ncd = calculate_ncd(c_test_text, c_train_text, combined_text)\n",
    "        distances.append(ncd)\n",
    "\n",
    "    sorted_idx = np.argsort(np.array(distances))\n",
    "    top_k_class = np.array(training_data['label'])[sorted_idx[:k]]\n",
    "    predicted_class = Counter(top_k_class).most_common(1)[0][0]\n",
    "    return predicted_class\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def batch_classify_texts(test_texts, training_data, k=2, sample_size=None):\n",
    "    if sample_size is not None and sample_size < len(training_data):\n",
    "        # Perform stratified sampling\n",
    "        _, stratified_sample = train_test_split(\n",
    "            training_data, \n",
    "            test_size=sample_size, \n",
    "            stratify=training_data['label'], \n",
    "            random_state=42\n",
    "        )\n",
    "        training_data = stratified_sample\n",
    "\n",
    "    probabilities = []\n",
    "    for test_text in test_texts:\n",
    "        c_test_text = compress_text(test_text)\n",
    "        distances = []\n",
    "\n",
    "        for _, row in training_data.iterrows():\n",
    "            c_train_text = row['compressed_length']\n",
    "            combined_text = test_text + \" \" + row['text']\n",
    "            ncd = calculate_ncd(c_test_text, c_train_text, combined_text)\n",
    "            distances.append(ncd)\n",
    "\n",
    "        sorted_idx = np.argsort(np.array(distances))\n",
    "        top_k_class = np.array(training_data['label'])[sorted_idx[:k]]\n",
    "        predicted_class = Counter(top_k_class).most_common(1)[0][0]\n",
    "        probabilities.append(predicted_class)\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def estimate_time_left(start_time, current_iter, total_iter):\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_iter = elapsed_time / current_iter\n",
    "    remaining_iters = total_iter - current_iter\n",
    "    estimated_time_left = avg_time_per_iter * remaining_iters\n",
    "    return estimated_time_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c3557f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:14:03.018072Z",
     "iopub.status.busy": "2023-11-25T08:14:03.017695Z",
     "iopub.status.idle": "2023-11-25T08:14:55.369975Z",
     "shell.execute_reply": "2023-11-25T08:14:55.368537Z"
    },
    "papermill": {
     "duration": 52.362874,
     "end_time": "2023-11-25T08:14:55.373631",
     "exception": false,
     "start_time": "2023-11-25T08:14:03.010757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing single evaluation:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:25<00:25, 25.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/2, Time left (est.): 25.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing single evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:52<00:00, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/2, Time left (est.): 0.00 seconds\n",
      "Single Evaluation AUROC Score: 0.9366697559468645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_k_fold = False\n",
    "debug_mode = True\n",
    "debug_size = 1000\n",
    "batch_size = 100\n",
    "\n",
    "if debug_mode:\n",
    "    debug_train = train.sample(n=debug_size, random_state=42)\n",
    "else:\n",
    "    debug_train = train\n",
    "\n",
    "if use_k_fold:\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    auroc_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(debug_train)):\n",
    "        start_time = time.time()\n",
    "        train_fold, val_fold = debug_train.iloc[train_index], debug_train.iloc[val_index]\n",
    "        val_texts = [text for text in val_fold['text']]\n",
    "        total_batches = len(val_texts) // batch_size + (len(val_texts) % batch_size != 0)\n",
    "\n",
    "        probabilities = []\n",
    "        for i in tqdm(range(total_batches), desc=f\"Processing fold {fold + 1}\"):\n",
    "            batch_texts = val_texts[i*batch_size:(i+1)*batch_size]\n",
    "            batch_probabilities = batch_classify_texts(batch_texts, train_fold, k=2)\n",
    "            probabilities.extend(batch_probabilities)\n",
    "\n",
    "            time_left = estimate_time_left(start_time, i + 1, total_batches)\n",
    "            print(f\"Fold {fold + 1}, Batch {i + 1}/{total_batches}, Time left (est.): {time_left:.2f} seconds\")\n",
    "\n",
    "        fold_auroc_score = roc_auc_score(val_fold['label'].values, probabilities)\n",
    "        auroc_scores.append(fold_auroc_score)\n",
    "\n",
    "    average_auroc_score = sum(auroc_scores) / len(auroc_scores)\n",
    "    print(\"Average AUROC Score:\", average_auroc_score)\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    train_single, val_single = train_test_split(debug_train, test_size=0.2, random_state=42)\n",
    "    val_texts = [text for text in val_single['text']]\n",
    "    total_batches = len(val_texts) // batch_size + (len(val_texts) % batch_size != 0)\n",
    "\n",
    "    probabilities = []\n",
    "    for i in tqdm(range(total_batches), desc=\"Processing single evaluation\"):\n",
    "        batch_texts = val_texts[i*batch_size:(i+1)*batch_size]\n",
    "        batch_probabilities = batch_classify_texts(batch_texts, train_single, k=2)\n",
    "        probabilities.extend(batch_probabilities)\n",
    "\n",
    "        time_left = estimate_time_left(start_time, i + 1, total_batches)\n",
    "        print(f\"Batch {i + 1}/{total_batches}, Time left (est.): {time_left:.2f} seconds\")\n",
    "\n",
    "    single_auroc_score = roc_auc_score(val_single['label'].values, probabilities)\n",
    "    print(\"Single Evaluation AUROC Score:\", single_auroc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f9ed59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:14:55.387943Z",
     "iopub.status.busy": "2023-11-25T08:14:55.386927Z",
     "iopub.status.idle": "2023-11-25T08:14:55.544509Z",
     "shell.execute_reply": "2023-11-25T08:14:55.543378Z"
    },
    "papermill": {
     "duration": 0.168251,
     "end_time": "2023-11-25T08:14:55.547741",
     "exception": false,
     "start_time": "2023-11-25T08:14:55.379490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# Generating predictions for the test set\n",
    "batch_size = 100\n",
    "sample_train_size = 150  # Adjust as needed (larger = slower)\n",
    "\n",
    "test_probabilities = []\n",
    "for i in tqdm.tqdm(range(0, len(test), batch_size), desc=\"Generating test predictions\"):\n",
    "    batch_texts = test['text'][i:i+batch_size].tolist()\n",
    "    batch_probabilities = batch_classify_texts(batch_texts, train, k=2, sample_size=sample_train_size)\n",
    "    test_probabilities.extend(batch_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a271affa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T08:14:55.562900Z",
     "iopub.status.busy": "2023-11-25T08:14:55.561808Z",
     "iopub.status.idle": "2023-11-25T08:14:55.574285Z",
     "shell.execute_reply": "2023-11-25T08:14:55.573052Z"
    },
    "papermill": {
     "duration": 0.023173,
     "end_time": "2023-11-25T08:14:55.577090",
     "exception": false,
     "start_time": "2023-11-25T08:14:55.553917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the submission file\n",
    "test['generated'] = test_probabilities\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'generated': test['generated']\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3945154,
     "sourceId": 6865136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.902231,
   "end_time": "2023-11-25T08:14:56.205474",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-25T08:13:44.303243",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
